---
phase: 07-cloud-run-deployment
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/knowledge_hub/cost.py
  - src/knowledge_hub/llm/processor.py
  - src/knowledge_hub/slack/notifier.py
  - src/knowledge_hub/slack/handlers.py
  - tests/test_cost.py
  - tests/test_llm/test_processor.py
  - tests/test_slack/test_notifier.py
autonomous: true
requirements:
  - DEPLOY-07

must_haves:
  truths:
    - "Every Gemini API call logs token usage and cost as structured JSON"
    - "Slack success notification includes total cost (e.g., 'Cost: $0.003')"
    - "Cost calculation uses Gemini 3 Flash pricing constants defined in one place"
  artifacts:
    - path: "src/knowledge_hub/cost.py"
      provides: "Token usage extraction, cost calculation, structured cost logging"
      contains: "extract_usage"
    - path: "tests/test_cost.py"
      provides: "Unit tests for cost calculation"
      contains: "test_extract_usage"
  key_links:
    - from: "src/knowledge_hub/llm/processor.py"
      to: "src/knowledge_hub/cost.py"
      via: "import extract_usage, log_usage"
      pattern: "from knowledge_hub.cost import"
    - from: "src/knowledge_hub/slack/notifier.py"
      to: "cost_usd parameter"
      via: "notify_success accepts cost_usd and includes in message"
      pattern: "cost_usd"
    - from: "src/knowledge_hub/slack/handlers.py"
      to: "cost_usd propagation"
      via: "process_message_urls passes cost from processor to notifier"
      pattern: "cost_usd"
---

<objective>
Add Gemini token usage tracking and cost calculation to the processing pipeline. Every Gemini call logs detailed token/cost data as structured JSON. Success notifications include the total cost.

Purpose: Meet DEPLOY-07 (Gemini token usage and cost per entry) and prepare cost data for the weekly digest and daily cost alert in Plan 03.
Output: cost.py module, updated processor.py returning cost, updated notifier.py displaying cost, tests.
</objective>

<execution_context>
@/Users/dbenger/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dbenger/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-cloud-run-deployment/07-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create cost module and wire into pipeline</name>
  <files>src/knowledge_hub/cost.py, src/knowledge_hub/llm/processor.py, src/knowledge_hub/slack/notifier.py, src/knowledge_hub/slack/handlers.py</files>
  <action>
1. Create `src/knowledge_hub/cost.py` with:
   - Gemini 3 Flash pricing constants (single source of truth):
     - `INPUT_PRICE_PER_TOKEN = 0.50 / 1_000_000` ($0.50 per 1M input tokens)
     - `OUTPUT_PRICE_PER_TOKEN = 3.00 / 1_000_000` ($3.00 per 1M output tokens)
   - `TokenUsage` dataclass with fields: `prompt_tokens: int`, `completion_tokens: int`, `total_tokens: int`, `cost_usd: float`
   - `extract_usage(response) -> TokenUsage` function:
     - Extract `response.usage_metadata.prompt_token_count` (default 0 if None)
     - Extract `response.usage_metadata.candidates_token_count` (default 0 if None)
     - Calculate cost: `(prompt * INPUT_PRICE) + (completion * OUTPUT_PRICE)`
     - Return `TokenUsage` with all fields
   - `log_usage(url: str, usage: TokenUsage) -> None` function:
     - Uses `logging.getLogger(__name__)`
     - Logs at INFO level: "Gemini processing complete"
     - Passes `extra` dict with: `url`, `model` (import GEMINI_MODEL from llm.prompts), `prompt_tokens`, `completion_tokens`, `total_tokens`, `cost_usd` (rounded to 6 decimal places)

2. Modify `src/knowledge_hub/llm/processor.py`:
   - Import `extract_usage`, `log_usage`, `TokenUsage` from `knowledge_hub.cost`
   - In `_call_gemini`: change to return a tuple `(LLMResponse, TokenUsage)`. Before `return response.parsed`, call `usage = extract_usage(response)` and `log_usage(url, usage)` -- but wait, _call_gemini doesn't have the URL. Instead:
   - Better approach: modify `_call_gemini` to return the raw response (not just `.parsed`). Then in `process_content`, extract parsed + usage from the raw response.
   - Actually simplest: modify `_call_gemini` to return `(response.parsed, response)` -- but tenacity retries need the function to return cleanly. Simplest: have `_call_gemini` return the full response object, then parse in `process_content`.
   - Final approach: `_call_gemini` returns the raw `GenerateContentResponse`. In `process_content`:
     ```python
     response = await _call_gemini(client, system_prompt, user_content)
     llm_result = response.parsed  # Validated LLMResponse
     usage = extract_usage(response)
     log_usage(content.url, usage)
     ```
   - Update `process_content` return type to `tuple[NotionPage, float]` where float is `cost_usd`. Return `(notion_page, usage.cost_usd)` at the end.
   - Update the function docstring to document the new return type.

3. Modify `src/knowledge_hub/slack/notifier.py`:
   - Update `notify_success` signature to accept optional `cost_usd: float | None = None`
   - When `cost_usd is not None`, append cost to the message text:
     ```python
     text = f"Saved to Notion: <{result.page_url}|{result.title}>"
     if cost_usd is not None:
         text += f" (Cost: ${cost_usd:.3f})"
     ```
   - This shows total cost only, no token breakdown (per user decision)

4. Modify `src/knowledge_hub/slack/handlers.py`:
   - In `process_message_urls`, update the LLM processing call:
     ```python
     notion_page, cost_usd = await process_content(gemini_client, content)
     ```
   - Pass `cost_usd` to `notify_success`:
     ```python
     await notify_success(channel_id, timestamp, result, cost_usd=cost_usd)
     ```
  </action>
  <verify>
Run `python -c "from knowledge_hub.cost import extract_usage, log_usage, TokenUsage"` imports without error. Run `uv run pytest tests/ -x` to confirm existing tests still pass (some processor tests may need updating due to return type change).
  </verify>
  <done>
cost.py exists with pricing constants, TokenUsage dataclass, extract_usage(), and log_usage(). processor.py returns (NotionPage, cost_usd). notifier.py includes cost in success message. handlers.py propagates cost through pipeline.
  </done>
</task>

<task type="auto">
  <name>Task 2: Tests for cost module and updated pipeline</name>
  <files>tests/test_cost.py, tests/test_llm/test_processor.py, tests/test_slack/test_notifier.py</files>
  <action>
1. Create `tests/test_cost.py` with:
   - `test_extract_usage_normal`: Mock a Gemini response with `usage_metadata` containing `prompt_token_count=100`, `candidates_token_count=50`. Verify TokenUsage has correct tokens and calculated cost: `(100 * 0.50/1M) + (50 * 3.00/1M) = 0.000200`.
   - `test_extract_usage_none_counts`: Mock response with None token counts. Verify defaults to 0 tokens and $0 cost.
   - `test_extract_usage_cost_precision`: Test with large token counts (1M input, 100K output) and verify cost matches expected: `$0.50 + $0.30 = $0.80`.
   - `test_log_usage_structured_output`: Patch logging, call `log_usage("https://example.com", usage)`, verify logger.info was called with "Gemini processing complete" and extra dict containing all expected fields.

2. Update `tests/test_llm/test_processor.py`:
   - All tests that call `process_content` need to unpack the new tuple return: `notion_page, cost_usd = await process_content(...)`.
   - The mock for `_call_gemini` now needs to return a mock response object (not just LLMResponse). Create a mock response with `.parsed` returning the LLMResponse and `.usage_metadata` with token counts.
   - Add `test_process_content_returns_cost`: Verify that process_content returns cost_usd as second element.
   - Ensure existing tests still verify all prior behavior (priority override, build_notion_page, etc.).

3. Update `tests/test_slack/test_notifier.py`:
   - Add `test_notify_success_with_cost`: Call `notify_success(channel, ts, result, cost_usd=0.003)`. Verify Slack message text includes "(Cost: $0.003)".
   - Add `test_notify_success_without_cost`: Call `notify_success(channel, ts, result)` (no cost). Verify message text does NOT include "Cost:".
   - Existing notifier tests should still pass unchanged since `cost_usd` defaults to None.

Run all tests with `uv run pytest tests/ -x` to confirm everything passes.
  </action>
  <verify>
`uv run pytest tests/ -x` passes all tests including new cost tests and updated processor/notifier tests. `uv run pytest tests/test_cost.py -v` shows all cost tests passing.
  </verify>
  <done>
test_cost.py has 4+ tests covering extraction, None handling, precision, and logging. test_processor.py updated for tuple return type. test_notifier.py has cost display tests. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_cost.py -v` -- all cost tests pass
2. `uv run pytest tests/test_llm/test_processor.py -v` -- all processor tests pass with new return type
3. `uv run pytest tests/test_slack/test_notifier.py -v` -- all notifier tests pass including cost display
4. `uv run pytest tests/ -x` -- full test suite passes
5. `grep "INPUT_PRICE_PER_TOKEN" src/knowledge_hub/cost.py` -- pricing constants exist
6. `grep "cost_usd" src/knowledge_hub/slack/notifier.py` -- cost parameter in notify_success
</verification>

<success_criteria>
- Every Gemini call extracts and logs token usage with structured fields
- Cost calculation uses centralized pricing constants (single source of truth)
- Success notification includes "(Cost: $X.XXX)" when cost is available
- Full test suite passes including new and updated tests
- Pipeline flow: processor returns cost -> handlers propagate -> notifier displays
</success_criteria>

<output>
After completion, create `.planning/phases/07-cloud-run-deployment/07-02-SUMMARY.md`
</output>
